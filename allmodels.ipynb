{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"LoanApprovalPrediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_result = pd.DataFrame(columns=['Model', 'Accuracy'])\n",
    "test_result = pd.DataFrame(columns=['Model', 'Accuracy'])\n",
    "\n",
    "training_result_up = pd.DataFrame(columns=['Model', 'Accuracy'])\n",
    "test_result_up= pd.DataFrame(columns=['Model', 'Accuracy'])\n",
    "\n",
    "training_result_down = pd.DataFrame(columns=['Model', 'Accuracy'])\n",
    "test_result_down = pd.DataFrame(columns=['Model', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>LP002978</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>LP002979</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>LP002983</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>8072</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>LP002984</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>7583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>LP002990</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID  Gender Married  Dependents     Education Self_Employed  \\\n",
       "0    LP001002    Male      No         0.0      Graduate            No   \n",
       "1    LP001003    Male     Yes         1.0      Graduate            No   \n",
       "2    LP001005    Male     Yes         0.0      Graduate           Yes   \n",
       "3    LP001006    Male     Yes         0.0  Not Graduate            No   \n",
       "4    LP001008    Male      No         0.0      Graduate            No   \n",
       "..        ...     ...     ...         ...           ...           ...   \n",
       "593  LP002978  Female      No         0.0      Graduate            No   \n",
       "594  LP002979    Male     Yes         3.0      Graduate            No   \n",
       "595  LP002983    Male     Yes         1.0      Graduate            No   \n",
       "596  LP002984    Male     Yes         2.0      Graduate            No   \n",
       "597  LP002990  Female      No         0.0      Graduate           Yes   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0               5849                0.0         NaN             360.0   \n",
       "1               4583             1508.0       128.0             360.0   \n",
       "2               3000                0.0        66.0             360.0   \n",
       "3               2583             2358.0       120.0             360.0   \n",
       "4               6000                0.0       141.0             360.0   \n",
       "..               ...                ...         ...               ...   \n",
       "593             2900                0.0        71.0             360.0   \n",
       "594             4106                0.0        40.0             180.0   \n",
       "595             8072              240.0       253.0             360.0   \n",
       "596             7583                0.0       187.0             360.0   \n",
       "597             4583                0.0       133.0             360.0   \n",
       "\n",
       "     Credit_History Property_Area Loan_Status  \n",
       "0               1.0         Urban           Y  \n",
       "1               1.0         Rural           N  \n",
       "2               1.0         Urban           Y  \n",
       "3               1.0         Urban           Y  \n",
       "4               1.0         Urban           Y  \n",
       "..              ...           ...         ...  \n",
       "593             1.0         Rural           Y  \n",
       "594             1.0         Rural           Y  \n",
       "595             1.0         Urban           Y  \n",
       "596             1.0         Urban           Y  \n",
       "597             0.0     Semiurban           N  \n",
       "\n",
       "[598 rows x 13 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3., nan])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Loan_ID'])\n",
    "df['Dependents'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               object\n",
       "Gender                object\n",
       "Married               object\n",
       "Dependents           float64\n",
       "Education             object\n",
       "Self_Employed         object\n",
       "ApplicantIncome        int64\n",
       "CoapplicantIncome    float64\n",
       "LoanAmount           float64\n",
       "Loan_Amount_Term     float64\n",
       "Credit_History       float64\n",
       "Property_Area         object\n",
       "Loan_Status           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan Id is irrelevant for prediction\n",
    "df.drop(['Loan_ID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHREYA\\AppData\\Local\\Temp\\ipykernel_17604\\2219162025.py:8: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x=id, data=df, palette='rainbow')\n",
      "C:\\Users\\SHREYA\\AppData\\Local\\Temp\\ipykernel_17604\\2219162025.py:8: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x=id, data=df, palette='rainbow')\n",
      "C:\\Users\\SHREYA\\AppData\\Local\\Temp\\ipykernel_17604\\2219162025.py:8: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x=id, data=df, palette='rainbow')\n",
      "C:\\Users\\SHREYA\\AppData\\Local\\Temp\\ipykernel_17604\\2219162025.py:8: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x=id, data=df, palette='rainbow')\n",
      "C:\\Users\\SHREYA\\AppData\\Local\\Temp\\ipykernel_17604\\2219162025.py:8: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x=id, data=df, palette='rainbow')\n",
      "C:\\Users\\SHREYA\\AppData\\Local\\Temp\\ipykernel_17604\\2219162025.py:8: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x=id, data=df, palette='rainbow')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# finding no. of categories in certain features\n",
    "obj = (df.dtypes == 'object')\n",
    "features = list(obj[obj].index)\n",
    "plt.figure(figsize=(18,10))\n",
    "i = 1\n",
    "for id in features:\n",
    "  plt.subplot(2,4,i)\n",
    "  sns.countplot(x=id, data=df, palette='rainbow')\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area', 'Loan_Status']\n"
     ]
    }
   ],
   "source": [
    "# handling categorical data\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "print(features)\n",
    "for id in features:\n",
    "  df[id] = label_encoder.fit_transform(df[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                 int32\n",
       "Married                int32\n",
       "Dependents           float64\n",
       "Education              int32\n",
       "Self_Employed          int32\n",
       "ApplicantIncome        int64\n",
       "CoapplicantIncome    float64\n",
       "LoanAmount           float64\n",
       "Loan_Amount_Term     float64\n",
       "Credit_History       float64\n",
       "Property_Area          int32\n",
       "Loan_Status            int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling missing values\n",
    "for col in df.columns:\n",
    "  df[col] = df[col].fillna(df[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nodata = df[df['Loan_Status'] == 0]\n",
    "yesdata = df[df['Loan_Status'] == 1]\n",
    "\n",
    "X = df.drop(['Loan_Status'],axis=1)\n",
    "Y = df['Loan_Status']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yesdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2192</td>\n",
       "      <td>1742.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3033</td>\n",
       "      <td>1459.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4583</td>\n",
       "      <td>5625.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1820</td>\n",
       "      <td>1719.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>341.917808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1863</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1875</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3814</td>\n",
       "      <td>1483.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "152       1        1         3.0          0              0            39999   \n",
       "507       1        1         2.0          1              0             2192   \n",
       "389       1        1         0.0          0              0             3033   \n",
       "156       1        1         0.0          0              0             4583   \n",
       "108       1        0         0.0          0              0             5316   \n",
       "..      ...      ...         ...        ...            ...              ...   \n",
       "414       1        1         0.0          0              0             1820   \n",
       "43        1        1         0.0          1              1             4695   \n",
       "157       1        1         0.0          1              0             1863   \n",
       "70        1        1         2.0          1              1             1875   \n",
       "492       1        1         0.0          1              0             3814   \n",
       "\n",
       "     CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "152                0.0       600.0        180.000000             0.0   \n",
       "507             1742.0        45.0        360.000000             1.0   \n",
       "389             1459.0        95.0        360.000000             1.0   \n",
       "156             5625.0       255.0        360.000000             1.0   \n",
       "108                0.0       136.0        360.000000             1.0   \n",
       "..                 ...         ...               ...             ...   \n",
       "414             1719.0       100.0        360.000000             1.0   \n",
       "43                 0.0        96.0        341.917808             1.0   \n",
       "157             1041.0        98.0        360.000000             1.0   \n",
       "70              1875.0        97.0        360.000000             1.0   \n",
       "492             1483.0       124.0        300.000000             1.0   \n",
       "\n",
       "     Property_Area  Loan_Status  \n",
       "152              1            1  \n",
       "507              1            1  \n",
       "389              2            1  \n",
       "156              1            1  \n",
       "108              2            1  \n",
       "..             ...          ...  \n",
       "414              2            1  \n",
       "43               2            1  \n",
       "157              1            1  \n",
       "70               1            1  \n",
       "492              1            1  \n",
       "\n",
       "[187 rows x 12 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "data_downsample = resample(yesdata, replace=True, n_samples=len(nodata), random_state=42)\n",
    "data_downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2192</td>\n",
       "      <td>1742.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3033</td>\n",
       "      <td>1459.0</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4583</td>\n",
       "      <td>5625.0</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6383</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.755973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>416</td>\n",
       "      <td>41667.0</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.843352</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2400</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>144.968804</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "0         1        1    3.000000          0              0            39999   \n",
       "1         1        1    2.000000          1              0             2192   \n",
       "2         1        1    0.000000          0              0             3033   \n",
       "3         1        1    0.000000          0              0             4583   \n",
       "4         1        0    0.000000          0              0             5316   \n",
       "..      ...      ...         ...        ...            ...              ...   \n",
       "369       1        1    2.000000          1              1             6383   \n",
       "370       1        0    0.755973          0              0             2987   \n",
       "371       0        0    3.000000          0              1              416   \n",
       "372       1        1    0.000000          1              0             2400   \n",
       "373       0        0    0.000000          0              1             4583   \n",
       "\n",
       "     CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0                  0.0  600.000000             180.0        0.000000   \n",
       "1               1742.0   45.000000             360.0        1.000000   \n",
       "2               1459.0   95.000000             360.0        1.000000   \n",
       "3               5625.0  255.000000             360.0        1.000000   \n",
       "4                  0.0  136.000000             360.0        1.000000   \n",
       "..                 ...         ...               ...             ...   \n",
       "369             1000.0  187.000000             360.0        1.000000   \n",
       "370                0.0   88.000000             360.0        0.000000   \n",
       "371            41667.0  350.000000             180.0        0.843352   \n",
       "372             3800.0  144.968804             180.0        1.000000   \n",
       "373                0.0  133.000000             360.0        0.000000   \n",
       "\n",
       "     Property_Area  Loan_Status  \n",
       "0                1            1  \n",
       "1                1            1  \n",
       "2                2            1  \n",
       "3                1            1  \n",
       "4                2            1  \n",
       "..             ...          ...  \n",
       "369              0            0  \n",
       "370              1            0  \n",
       "371              2            0  \n",
       "372              2            0  \n",
       "373              1            0  \n",
       "\n",
       "[374 rows x 12 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_downsample = pd.concat([data_downsample, nodata], ignore_index= True)\n",
    "data_downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2647</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4283</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>2541.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1828</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>341.917808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4283</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3430</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1828</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>341.917808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "332       1        1         3.0          1              0             2647   \n",
       "571       1        1         1.0          0              0             4283   \n",
       "292       0        0         0.0          0              0             5000   \n",
       "35        1        1         0.0          0              0             1828   \n",
       "345       0        1         0.0          0              1             5500   \n",
       "..      ...      ...         ...        ...            ...              ...   \n",
       "571       1        1         1.0          0              0             4283   \n",
       "551       1        1         2.0          0              0             8799   \n",
       "206       1        1         3.0          0              0             3430   \n",
       "35        1        1         0.0          0              0             1828   \n",
       "165       1        0         0.0          0              0             2237   \n",
       "\n",
       "     CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "332             1587.0       173.0        360.000000             1.0   \n",
       "571             3000.0       172.0         84.000000             1.0   \n",
       "292             2541.0       151.0        480.000000             1.0   \n",
       "35              1330.0       100.0        341.917808             0.0   \n",
       "345                0.0       105.0        360.000000             0.0   \n",
       "..                 ...         ...               ...             ...   \n",
       "571             3000.0       172.0         84.000000             1.0   \n",
       "551                0.0       258.0        360.000000             0.0   \n",
       "206             1250.0       128.0        360.000000             0.0   \n",
       "35              1330.0       100.0        341.917808             0.0   \n",
       "165                0.0        63.0        480.000000             0.0   \n",
       "\n",
       "     Property_Area  Loan_Status  \n",
       "332              0            0  \n",
       "571              0            0  \n",
       "292              0            0  \n",
       "35               2            0  \n",
       "345              0            0  \n",
       "..             ...          ...  \n",
       "571              0            0  \n",
       "551              2            0  \n",
       "206              1            0  \n",
       "35               2            0  \n",
       "165              1            0  \n",
       "\n",
       "[411 rows x 12 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_upsample = resample(nodata, replace=True, n_samples=len(yesdata), random_state=42)\n",
    "data_upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2647</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4283</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>2541.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1828</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>341.917808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3232</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8072</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "0         1        1         3.0          1              0             2647   \n",
       "1         1        1         1.0          0              0             4283   \n",
       "2         0        0         0.0          0              0             5000   \n",
       "3         1        1         0.0          0              0             1828   \n",
       "4         0        1         0.0          0              1             5500   \n",
       "..      ...      ...         ...        ...            ...              ...   \n",
       "817       1        1         0.0          0              0             3232   \n",
       "818       0        0         0.0          0              0             2900   \n",
       "819       1        1         3.0          0              0             4106   \n",
       "820       1        1         1.0          0              0             8072   \n",
       "821       1        1         2.0          0              0             7583   \n",
       "\n",
       "     CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0               1587.0       173.0        360.000000             1.0   \n",
       "1               3000.0       172.0         84.000000             1.0   \n",
       "2               2541.0       151.0        480.000000             1.0   \n",
       "3               1330.0       100.0        341.917808             0.0   \n",
       "4                  0.0       105.0        360.000000             0.0   \n",
       "..                 ...         ...               ...             ...   \n",
       "817             1950.0       108.0        360.000000             1.0   \n",
       "818                0.0        71.0        360.000000             1.0   \n",
       "819                0.0        40.0        180.000000             1.0   \n",
       "820              240.0       253.0        360.000000             1.0   \n",
       "821                0.0       187.0        360.000000             1.0   \n",
       "\n",
       "     Property_Area  Loan_Status  \n",
       "0                0            0  \n",
       "1                0            0  \n",
       "2                0            0  \n",
       "3                2            0  \n",
       "4                0            0  \n",
       "..             ...          ...  \n",
       "817              0            1  \n",
       "818              0            1  \n",
       "819              0            1  \n",
       "820              2            1  \n",
       "821              2            1  \n",
       "\n",
       "[822 rows x 12 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_upsample= pd.concat([data_upsample, yesdata], ignore_index= True)\n",
    "data_upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of KNN is =  76.77824267782427\n",
      "Test accuracy score of KNN is =  83.33333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHREYA\\AppData\\Local\\Temp\\ipykernel_17604\\454775817.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  training_result = pd.concat([training_result, dff1], ignore_index=True)\n",
      "C:\\Users\\SHREYA\\AppData\\Local\\Temp\\ipykernel_17604\\454775817.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_result = pd.concat([test_result, dff2], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=25)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "\n",
    "Y_train_pred = knn.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of KNN is = \", acc1)\n",
    "print(\"Test accuracy score of KNN is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"KNN\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"KNN\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result = pd.concat([training_result, dff1], ignore_index=True)\n",
    "test_result = pd.concat([test_result, dff2], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Random Forest is =  100.0\n",
      "Test accuracy score of Random Forest is =  83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 96,criterion = 'entropy',\n",
    "                            random_state = 20, max_depth=50)\n",
    "rfc.fit(X_train, Y_train)\n",
    "Y_pred = rfc.predict(X_test)\n",
    "Y_train_pred = rfc.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Random Forest is = \", acc1)\n",
    "print(\"Test accuracy score of Random Forest is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"Random Forest\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Random Forest\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result = pd.concat([training_result, dff1], ignore_index=True)\n",
    "test_result = pd.concat([test_result, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "lc = LogisticRegression(max_iter = 221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of SVM is =  79.49790794979079\n",
      "Test accuracy score of SVM is =  85.83333333333333\n"
     ]
    }
   ],
   "source": [
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "Y_train_pred = svc.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of SVM is = \", acc1)\n",
    "print(\"Test accuracy score of SVM is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"SVM\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"SVM\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result = pd.concat([training_result, dff1], ignore_index=True)\n",
    "test_result = pd.concat([test_result, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Logistic Regression is =  79.70711297071131\n",
      "Test accuracy score of Logistic Regression is =  85.83333333333333\n"
     ]
    }
   ],
   "source": [
    "lc.fit(X_train, Y_train)\n",
    "Y_pred = lc.predict(X_test)\n",
    "Y_train_pred = lc.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Logistic Regression is = \", acc1)\n",
    "print(\"Test accuracy score of Logistic Regression is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"Logistic Regression\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Logistic Regression\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result = pd.concat([training_result, dff1], ignore_index=True)\n",
    "test_result = pd.concat([test_result, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Gaussian Naive Bayes is =  79.2887029288703\n",
      "Test accuracy score of Gaussian Naive Bayes is =  83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = gnb.predict(X_test)\n",
    "Y_train_pred = gnb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Gaussian Naive Bayes is = \", acc1)\n",
    "print(\"Test accuracy score of Gaussian Naive Bayes is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"Gaussian Naive Bayes\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Gaussian Naive Bayes\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result = pd.concat([training_result, dff1], ignore_index=True)\n",
    "test_result = pd.concat([test_result, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Multinomial Naive Bayes is =  69.24686192468619\n",
      "Test accuracy score of Multinomial Naive Bayes is =  74.16666666666667\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = mnb.predict(X_test)\n",
    "Y_train_pred = mnb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Multinomial Naive Bayes is = \", acc1)\n",
    "print(\"Test accuracy score of Multinomial Naive Bayes is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"Multinomial Naive Bayes\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Multinomial Naive Bayes\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result = pd.concat([training_result, dff1], ignore_index=True)\n",
    "test_result = pd.concat([test_result, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Bernoulli Naive Bayes is =  79.9163179916318\n",
      "Test accuracy score of Bernoulli Naive Bayes is =  83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = bnb.predict(X_test)\n",
    "Y_train_pred = bnb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Bernoulli Naive Bayes is = \", acc1)\n",
    "print(\"Test accuracy score of Bernoulli Naive Bayes is = \", acc2)\n",
    "\n",
    "\n",
    "dict1 = {'Model': [\"Bernoulli Naive Bayes\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Bernoulli Naive Bayes\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result = pd.concat([training_result, dff1], ignore_index=True)\n",
    "test_result = pd.concat([test_result, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Decision Tree is =  82.00836820083683\n",
      "Test accuracy score of Decision Tree is =  80.83333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=8, max_leaf_nodes=10, max_features=12, random_state=7777)\n",
    "dt.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = dt.predict(X_test)\n",
    "Y_train_pred = dt.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Decision Tree is = \", acc1)\n",
    "print(\"Test accuracy score of Decision Tree is = \", acc2)\n",
    "\n",
    "\n",
    "dict1 = {'Model': [\"Decision Tree\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Decision Tree\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result = pd.concat([training_result, dff1], ignore_index=True)\n",
    "test_result = pd.concat([test_result, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Bagging Classifier is =  80.1255230125523\n",
      "Test accuracy score of Bagging Classifier is =  85.83333333333333\n"
     ]
    }
   ],
   "source": [
    "bg=BaggingClassifier(RandomForestClassifier(min_samples_split=5,max_depth=6),max_samples=0.5,max_features=1.0,n_estimators=10)\n",
    "bg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = bg.predict(X_test)\n",
    "Y_train_pred = bg.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Bagging Classifier is = \", acc1)\n",
    "print(\"Test accuracy score of Bagging Classifier is = \", acc2)\n",
    "\n",
    "\n",
    "dict1 = {'Model': [\"Bagging Classifier\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Bagging Classifier\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result = pd.concat([training_result, dff1], ignore_index=True)\n",
    "test_result = pd.concat([test_result, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of AdaBoost is =  84.93723849372385\n",
      "Test accuracy score of AdaBoost is =  79.16666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHREYA\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = ada.predict(X_test)\n",
    "Y_train_pred = ada.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of AdaBoost is = \", acc1)\n",
    "print(\"Test accuracy score of AdaBoost is = \", acc2)\n",
    "\n",
    "\n",
    "dict1 = {'Model': [\"AdaBoost\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"AdaBoost\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result = pd.concat([training_result, dff1], ignore_index=True)\n",
    "test_result = pd.concat([test_result, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Gradient Boosting is =  88.91213389121339\n",
      "Test accuracy score of Gradient Boosting is =  82.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gdb = GradientBoostingClassifier(n_estimators=100)\n",
    "gdb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = gdb.predict(X_test)\n",
    "Y_train_pred = gdb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Gradient Boosting is = \", acc1)\n",
    "print(\"Test accuracy score of Gradient Boosting is = \", acc2)\n",
    "\n",
    "\n",
    "dict1 = {'Model': [\"Gradient Boosting\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Gradient Boosting\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result = pd.concat([training_result, dff1], ignore_index=True)\n",
    "test_result = pd.concat([test_result, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mCat\u001b[39;00m \n\u001b[0;32m      2\u001b[0m cb \u001b[38;5;241m=\u001b[39m Cat\u001b[38;5;241m.\u001b[39mCatBoostClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7777\u001b[39m, iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.048\u001b[39m)\n\u001b[0;32m      4\u001b[0m cb\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "import catboost as Cat \n",
    "cb = Cat.CatBoostClassifier(random_state=7777, iterations=150, learning_rate=0.048)\n",
    "\n",
    "cb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = cb.predict(X_test)\n",
    "Y_train_pred = cb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of CatBoost is = \", acc1)\n",
    "print(\"Test accuracy score of CatBoost is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"CatBoost\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"CatBoost\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result = pd.concat([training_result, dff1], ignore_index=True)\n",
    "test_result = pd.concat([test_result, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import layers\n",
    "# from keras import models\n",
    "# from keras import optimizers\n",
    "# from keras import losses\n",
    "# from keras import regularizers\n",
    "# from keras import metrics\n",
    "# from tqdm.keras import TqdmCallback\n",
    "\n",
    "# # add validation dataset\n",
    "# validation_split=100\n",
    "# x_validation=X[:validation_split]\n",
    "# x_partial_train=X[validation_split:]\n",
    "# y_validation=Y[:validation_split]\n",
    "# y_partial_train=Y[validation_split:]\n",
    "\n",
    "# # build & compile model\n",
    "# model=models.Sequential()\n",
    "# model.add(layers.Dense(6,kernel_regularizer=regularizers.l2(0.003),activation='relu',input_shape=(11,)))\n",
    "# model.add(layers.Dropout(0.65))\n",
    "# model.add(layers.Dense(6,kernel_regularizer=regularizers.l2(0.003),activation='relu'))\n",
    "# model.add(layers.Dropout(0.65))\n",
    "# model.add(layers.Dense(1,activation='sigmoid'))\n",
    "# model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# # fir the model\n",
    "# model.fit(x_partial_train,y_partial_train,epochs=100,batch_size=50,validation_data=(x_validation,y_validation), callbacks=[TqdmCallback(verbose=0)],verbose=0)\n",
    "\n",
    "# print('')\n",
    "# print(\"score on test: \" + str(model.evaluate(X_test,Y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of XGBoost is =  100.0\n",
      "Test accuracy score of XGBoost is =  77.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as XGBoost\n",
    "xgb = XGBoost.XGBClassifier()\n",
    "\n",
    "xgb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = xgb.predict(X_test)\n",
    "Y_train_pred = xgb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of XGBoost is = \", acc1)\n",
    "print(\"Test accuracy score of XGBoost is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"XGBoost\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"XGBoost\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result = pd.concat([training_result, dff1], ignore_index=True)\n",
    "test_result = pd.concat([test_result, dff2], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                      Model    Accuracy\n",
       " 0                       KNN   76.778243\n",
       " 1             Random Forest  100.000000\n",
       " 2                       SVM   79.916318\n",
       " 3       Logistic Regression   79.707113\n",
       " 4      Gaussian Naive Bayes   79.288703\n",
       " 5   Multinomial Naive Bayes   69.246862\n",
       " 6     Bernoulli Naive Bayes   79.916318\n",
       " 7             Decision Tree   82.008368\n",
       " 8        Bagging Classifier   80.125523\n",
       " 9                  AdaBoost   84.937238\n",
       " 10        Gradient Boosting   88.912134\n",
       " 11                 CatBoost   80.962343\n",
       " 12                  XGBoost  100.000000,\n",
       "                       Model   Accuracy\n",
       " 0                       KNN  83.333333\n",
       " 1             Random Forest  83.333333\n",
       " 2                       SVM  85.833333\n",
       " 3       Logistic Regression  85.833333\n",
       " 4      Gaussian Naive Bayes  83.333333\n",
       " 5   Multinomial Naive Bayes  74.166667\n",
       " 6     Bernoulli Naive Bayes  83.333333\n",
       " 7             Decision Tree  80.833333\n",
       " 8        Bagging Classifier  85.000000\n",
       " 9                  AdaBoost  79.166667\n",
       " 10        Gradient Boosting  81.666667\n",
       " 11                 CatBoost  85.833333\n",
       " 12                  XGBoost  77.500000)"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_result, test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_upsample.drop(['Loan_Status'],axis=1)\n",
    "Y = data_upsample['Loan_Status']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of KNN is =  74.1248097412481\n",
      "Test accuracy score of KNN is =  69.0909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanidhya\\AppData\\Local\\Temp\\ipykernel_5204\\499755671.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  training_result_up = pd.concat([training_result_up, dff1], ignore_index=True)\n",
      "C:\\Users\\Sanidhya\\AppData\\Local\\Temp\\ipykernel_5204\\499755671.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_result_up = pd.concat([test_result_up, dff2], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=25)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "\n",
    "Y_train_pred = knn.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of KNN is = \", acc1)\n",
    "print(\"Test accuracy score of KNN is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"KNN\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"KNN\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_up = pd.concat([training_result_up, dff1], ignore_index=True)\n",
    "test_result_up = pd.concat([test_result_up, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Random Forest is =  100.0\n",
      "Test accuracy score of Random Forest is =  90.9090909090909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 96,criterion = 'entropy',\n",
    "                            random_state = 20, max_depth=50)\n",
    "rfc.fit(X_train, Y_train)\n",
    "Y_pred = rfc.predict(X_test)\n",
    "Y_train_pred = rfc.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Random Forest is = \", acc1)\n",
    "print(\"Test accuracy score of Random Forest is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"Random Forest\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Random Forest\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_up = pd.concat([training_result_up, dff1], ignore_index=True)\n",
    "test_result_up = pd.concat([test_result_up, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "svc = SVC(kernel='poly', degree=3)\n",
    "lc = LogisticRegression(max_iter = 221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of SVM is =  75.79908675799086\n",
      "Test accuracy score of SVM is =  74.54545454545455\n"
     ]
    }
   ],
   "source": [
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "Y_train_pred = svc.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of SVM is = \", acc1)\n",
    "print(\"Test accuracy score of SVM is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"SVM\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"SVM\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_up = pd.concat([training_result_up, dff1], ignore_index=True)\n",
    "test_result_up = pd.concat([test_result_up, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Logistic Regression is =  72.14611872146118\n",
      "Test accuracy score of Logistic Regression is =  73.93939393939394\n"
     ]
    }
   ],
   "source": [
    "lc.fit(X_train, Y_train)\n",
    "Y_pred = lc.predict(X_test)\n",
    "Y_train_pred = lc.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Logistic Regression is = \", acc1)\n",
    "print(\"Test accuracy score of Logistic Regression is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"Logistic Regression\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Logistic Regression\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_up = pd.concat([training_result_up, dff1], ignore_index=True)\n",
    "test_result_up = pd.concat([test_result_up, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Gaussian Naive Bayes is =  73.36377473363774\n",
      "Test accuracy score of Gaussian Naive Bayes is =  72.72727272727273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = gnb.predict(X_test)\n",
    "Y_train_pred = gnb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Gaussian Naive Bayes is = \", acc1)\n",
    "print(\"Test accuracy score of Gaussian Naive Bayes is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"Gaussian Naive Bayes\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Gaussian Naive Bayes\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_up = pd.concat([training_result_up, dff1], ignore_index=True)\n",
    "test_result_up = pd.concat([test_result_up, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Multinomial Naive Bayes is =  64.84018264840182\n",
      "Test accuracy score of Multinomial Naive Bayes is =  61.212121212121204\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = mnb.predict(X_test)\n",
    "Y_train_pred = mnb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Multinomial Naive Bayes is = \", acc1)\n",
    "print(\"Test accuracy score of Multinomial Naive Bayes is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"Multinomial Naive Bayes\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Multinomial Naive Bayes\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_up = pd.concat([training_result_up, dff1], ignore_index=True)\n",
    "test_result_up = pd.concat([test_result_up, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Bernoulli Naive Bayes is =  70.62404870624049\n",
      "Test accuracy score of Bernoulli Naive Bayes is =  77.57575757575758\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = bnb.predict(X_test)\n",
    "Y_train_pred = bnb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Bernoulli Naive Bayes is = \", acc1)\n",
    "print(\"Test accuracy score of Bernoulli Naive Bayes is = \", acc2)\n",
    "\n",
    "\n",
    "dict1 = {'Model': [\"Bernoulli Naive Bayes\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Bernoulli Naive Bayes\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_up = pd.concat([training_result_up, dff1], ignore_index=True)\n",
    "test_result_up = pd.concat([test_result_up, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Decision Tree is =  78.99543378995433\n",
      "Test accuracy score of Decision Tree is =  73.93939393939394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=8, max_leaf_nodes=10, max_features=12, random_state=7777)\n",
    "dt.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = dt.predict(X_test)\n",
    "Y_train_pred = dt.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Decision Tree is = \", acc1)\n",
    "print(\"Test accuracy score of Decision Tree is = \", acc2)\n",
    "\n",
    "\n",
    "dict1 = {'Model': [\"Decision Tree\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Decision Tree\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_up = pd.concat([training_result_up, dff1], ignore_index=True)\n",
    "test_result_up = pd.concat([test_result_up, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Bagging Classifier is =  84.62709284627093\n",
      "Test accuracy score of Bagging Classifier is =  80.60606060606061\n"
     ]
    }
   ],
   "source": [
    "bg=BaggingClassifier(RandomForestClassifier(min_samples_split=5,max_depth=6),max_samples=0.5,max_features=1.0,n_estimators=10)\n",
    "bg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = bg.predict(X_test)\n",
    "Y_train_pred = bg.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Bagging Classifier is = \", acc1)\n",
    "print(\"Test accuracy score of Bagging Classifier is = \", acc2)\n",
    "\n",
    "\n",
    "dict1 = {'Model': [\"Bagging Classifier\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Bagging Classifier\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_up = pd.concat([training_result_up, dff1], ignore_index=True)\n",
    "test_result_up = pd.concat([test_result_up, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of AdaBoost is =  82.95281582952816\n",
      "Test accuracy score of AdaBoost is =  75.75757575757575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = ada.predict(X_test)\n",
    "Y_train_pred = ada.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of AdaBoost is = \", acc1)\n",
    "print(\"Test accuracy score of AdaBoost is = \", acc2)\n",
    "\n",
    "\n",
    "dict1 = {'Model': [\"AdaBoost\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"AdaBoost\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_up = pd.concat([training_result_up, dff1], ignore_index=True)\n",
    "test_result_up = pd.concat([test_result_up, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Gradient Boosting is =  92.08523592085236\n",
      "Test accuracy score of Gradient Boosting is =  82.42424242424242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gdb = GradientBoostingClassifier(n_estimators=100)\n",
    "gdb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = gdb.predict(X_test)\n",
    "Y_train_pred = gdb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Gradient Boosting is = \", acc1)\n",
    "print(\"Test accuracy score of Gradient Boosting is = \", acc2)\n",
    "\n",
    "\n",
    "dict1 = {'Model': [\"Gradient Boosting\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Gradient Boosting\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_up = pd.concat([training_result_up, dff1], ignore_index=True)\n",
    "test_result_up = pd.concat([test_result_up, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6823533\ttotal: 2.23ms\tremaining: 332ms\n",
      "1:\tlearn: 0.6751273\ttotal: 5.81ms\tremaining: 430ms\n",
      "2:\tlearn: 0.6646145\ttotal: 7.77ms\tremaining: 381ms\n",
      "3:\tlearn: 0.6556992\ttotal: 9.95ms\tremaining: 363ms\n",
      "4:\tlearn: 0.6462249\ttotal: 12.5ms\tremaining: 362ms\n",
      "5:\tlearn: 0.6362955\ttotal: 14.3ms\tremaining: 343ms\n",
      "6:\tlearn: 0.6279659\ttotal: 16.2ms\tremaining: 331ms\n",
      "7:\tlearn: 0.6219749\ttotal: 18.3ms\tremaining: 325ms\n",
      "8:\tlearn: 0.6143680\ttotal: 21ms\tremaining: 329ms\n",
      "9:\tlearn: 0.6082852\ttotal: 23.3ms\tremaining: 326ms\n",
      "10:\tlearn: 0.6020659\ttotal: 26.2ms\tremaining: 331ms\n",
      "11:\tlearn: 0.5956818\ttotal: 28.2ms\tremaining: 324ms\n",
      "12:\tlearn: 0.5894618\ttotal: 30ms\tremaining: 316ms\n",
      "13:\tlearn: 0.5838464\ttotal: 32ms\tremaining: 311ms\n",
      "14:\tlearn: 0.5786463\ttotal: 33.9ms\tremaining: 305ms\n",
      "15:\tlearn: 0.5738519\ttotal: 36ms\tremaining: 301ms\n",
      "16:\tlearn: 0.5690677\ttotal: 39.1ms\tremaining: 306ms\n",
      "17:\tlearn: 0.5630343\ttotal: 42.1ms\tremaining: 308ms\n",
      "18:\tlearn: 0.5586562\ttotal: 43.3ms\tremaining: 298ms\n",
      "19:\tlearn: 0.5541721\ttotal: 45.3ms\tremaining: 295ms\n",
      "20:\tlearn: 0.5494162\ttotal: 47ms\tremaining: 289ms\n",
      "21:\tlearn: 0.5455398\ttotal: 48.3ms\tremaining: 281ms\n",
      "22:\tlearn: 0.5412101\ttotal: 49.6ms\tremaining: 274ms\n",
      "23:\tlearn: 0.5380602\ttotal: 50.2ms\tremaining: 264ms\n",
      "24:\tlearn: 0.5345142\ttotal: 52.1ms\tremaining: 260ms\n",
      "25:\tlearn: 0.5306466\ttotal: 54.8ms\tremaining: 261ms\n",
      "26:\tlearn: 0.5270614\ttotal: 56.9ms\tremaining: 259ms\n",
      "27:\tlearn: 0.5239441\ttotal: 58.3ms\tremaining: 254ms\n",
      "28:\tlearn: 0.5212686\ttotal: 58.7ms\tremaining: 245ms\n",
      "29:\tlearn: 0.5176980\ttotal: 60ms\tremaining: 240ms\n",
      "30:\tlearn: 0.5140195\ttotal: 61.2ms\tremaining: 235ms\n",
      "31:\tlearn: 0.5108867\ttotal: 62.6ms\tremaining: 231ms\n",
      "32:\tlearn: 0.5071425\ttotal: 64.2ms\tremaining: 227ms\n",
      "33:\tlearn: 0.5044458\ttotal: 66ms\tremaining: 225ms\n",
      "34:\tlearn: 0.5028053\ttotal: 67.9ms\tremaining: 223ms\n",
      "35:\tlearn: 0.4993408\ttotal: 70.2ms\tremaining: 222ms\n",
      "36:\tlearn: 0.4968061\ttotal: 71.9ms\tremaining: 220ms\n",
      "37:\tlearn: 0.4945523\ttotal: 73.6ms\tremaining: 217ms\n",
      "38:\tlearn: 0.4921257\ttotal: 74.9ms\tremaining: 213ms\n",
      "39:\tlearn: 0.4901595\ttotal: 76.3ms\tremaining: 210ms\n",
      "40:\tlearn: 0.4883582\ttotal: 77.6ms\tremaining: 206ms\n",
      "41:\tlearn: 0.4861433\ttotal: 79.1ms\tremaining: 203ms\n",
      "42:\tlearn: 0.4831104\ttotal: 80.4ms\tremaining: 200ms\n",
      "43:\tlearn: 0.4815781\ttotal: 81.7ms\tremaining: 197ms\n",
      "44:\tlearn: 0.4790966\ttotal: 84.6ms\tremaining: 197ms\n",
      "45:\tlearn: 0.4769214\ttotal: 86.1ms\tremaining: 195ms\n",
      "46:\tlearn: 0.4747842\ttotal: 87.4ms\tremaining: 192ms\n",
      "47:\tlearn: 0.4725301\ttotal: 88.6ms\tremaining: 188ms\n",
      "48:\tlearn: 0.4703676\ttotal: 90ms\tremaining: 185ms\n",
      "49:\tlearn: 0.4678164\ttotal: 91.5ms\tremaining: 183ms\n",
      "50:\tlearn: 0.4659057\ttotal: 93.3ms\tremaining: 181ms\n",
      "51:\tlearn: 0.4636257\ttotal: 95.8ms\tremaining: 180ms\n",
      "52:\tlearn: 0.4620583\ttotal: 97.3ms\tremaining: 178ms\n",
      "53:\tlearn: 0.4607616\ttotal: 100ms\tremaining: 178ms\n",
      "54:\tlearn: 0.4585457\ttotal: 102ms\tremaining: 176ms\n",
      "55:\tlearn: 0.4567164\ttotal: 103ms\tremaining: 173ms\n",
      "56:\tlearn: 0.4541832\ttotal: 104ms\tremaining: 170ms\n",
      "57:\tlearn: 0.4523915\ttotal: 106ms\tremaining: 168ms\n",
      "58:\tlearn: 0.4505101\ttotal: 107ms\tremaining: 165ms\n",
      "59:\tlearn: 0.4491822\ttotal: 109ms\tremaining: 164ms\n",
      "60:\tlearn: 0.4476411\ttotal: 111ms\tremaining: 161ms\n",
      "61:\tlearn: 0.4465772\ttotal: 112ms\tremaining: 159ms\n",
      "62:\tlearn: 0.4450368\ttotal: 114ms\tremaining: 158ms\n",
      "63:\tlearn: 0.4443201\ttotal: 116ms\tremaining: 156ms\n",
      "64:\tlearn: 0.4428803\ttotal: 118ms\tremaining: 154ms\n",
      "65:\tlearn: 0.4417403\ttotal: 120ms\tremaining: 152ms\n",
      "66:\tlearn: 0.4410018\ttotal: 121ms\tremaining: 150ms\n",
      "67:\tlearn: 0.4395864\ttotal: 122ms\tremaining: 147ms\n",
      "68:\tlearn: 0.4392876\ttotal: 123ms\tremaining: 144ms\n",
      "69:\tlearn: 0.4379712\ttotal: 125ms\tremaining: 142ms\n",
      "70:\tlearn: 0.4366145\ttotal: 126ms\tremaining: 140ms\n",
      "71:\tlearn: 0.4352393\ttotal: 127ms\tremaining: 138ms\n",
      "72:\tlearn: 0.4340676\ttotal: 130ms\tremaining: 137ms\n",
      "73:\tlearn: 0.4323881\ttotal: 131ms\tremaining: 135ms\n",
      "74:\tlearn: 0.4314858\ttotal: 133ms\tremaining: 133ms\n",
      "75:\tlearn: 0.4301081\ttotal: 134ms\tremaining: 130ms\n",
      "76:\tlearn: 0.4292418\ttotal: 135ms\tremaining: 128ms\n",
      "77:\tlearn: 0.4285418\ttotal: 137ms\tremaining: 126ms\n",
      "78:\tlearn: 0.4278461\ttotal: 138ms\tremaining: 124ms\n",
      "79:\tlearn: 0.4267261\ttotal: 140ms\tremaining: 122ms\n",
      "80:\tlearn: 0.4258483\ttotal: 141ms\tremaining: 120ms\n",
      "81:\tlearn: 0.4245314\ttotal: 142ms\tremaining: 118ms\n",
      "82:\tlearn: 0.4238071\ttotal: 145ms\tremaining: 117ms\n",
      "83:\tlearn: 0.4225841\ttotal: 147ms\tremaining: 115ms\n",
      "84:\tlearn: 0.4215497\ttotal: 148ms\tremaining: 113ms\n",
      "85:\tlearn: 0.4204519\ttotal: 149ms\tremaining: 111ms\n",
      "86:\tlearn: 0.4191202\ttotal: 151ms\tremaining: 109ms\n",
      "87:\tlearn: 0.4181825\ttotal: 153ms\tremaining: 108ms\n",
      "88:\tlearn: 0.4174497\ttotal: 154ms\tremaining: 106ms\n",
      "89:\tlearn: 0.4161369\ttotal: 156ms\tremaining: 104ms\n",
      "90:\tlearn: 0.4145867\ttotal: 158ms\tremaining: 102ms\n",
      "91:\tlearn: 0.4136019\ttotal: 160ms\tremaining: 101ms\n",
      "92:\tlearn: 0.4124364\ttotal: 161ms\tremaining: 98.7ms\n",
      "93:\tlearn: 0.4115229\ttotal: 163ms\tremaining: 96.9ms\n",
      "94:\tlearn: 0.4109410\ttotal: 165ms\tremaining: 95.3ms\n",
      "95:\tlearn: 0.4096003\ttotal: 166ms\tremaining: 93.5ms\n",
      "96:\tlearn: 0.4082769\ttotal: 168ms\tremaining: 91.6ms\n",
      "97:\tlearn: 0.4070199\ttotal: 169ms\tremaining: 89.7ms\n",
      "98:\tlearn: 0.4060441\ttotal: 170ms\tremaining: 87.8ms\n",
      "99:\tlearn: 0.4055329\ttotal: 172ms\tremaining: 85.9ms\n",
      "100:\tlearn: 0.4042752\ttotal: 175ms\tremaining: 84.8ms\n",
      "101:\tlearn: 0.4029475\ttotal: 176ms\tremaining: 83.1ms\n",
      "102:\tlearn: 0.4018520\ttotal: 178ms\tremaining: 81.4ms\n",
      "103:\tlearn: 0.4001596\ttotal: 180ms\tremaining: 79.7ms\n",
      "104:\tlearn: 0.3995401\ttotal: 182ms\tremaining: 77.9ms\n",
      "105:\tlearn: 0.3990132\ttotal: 183ms\tremaining: 75.9ms\n",
      "106:\tlearn: 0.3976082\ttotal: 184ms\tremaining: 74.1ms\n",
      "107:\tlearn: 0.3963728\ttotal: 186ms\tremaining: 72.2ms\n",
      "108:\tlearn: 0.3951912\ttotal: 187ms\tremaining: 70.3ms\n",
      "109:\tlearn: 0.3948768\ttotal: 187ms\tremaining: 68.1ms\n",
      "110:\tlearn: 0.3936573\ttotal: 190ms\tremaining: 66.6ms\n",
      "111:\tlearn: 0.3931511\ttotal: 191ms\tremaining: 64.9ms\n",
      "112:\tlearn: 0.3915721\ttotal: 193ms\tremaining: 63.2ms\n",
      "113:\tlearn: 0.3903591\ttotal: 195ms\tremaining: 61.4ms\n",
      "114:\tlearn: 0.3893784\ttotal: 196ms\tremaining: 59.6ms\n",
      "115:\tlearn: 0.3882416\ttotal: 197ms\tremaining: 57.8ms\n",
      "116:\tlearn: 0.3870523\ttotal: 199ms\tremaining: 56.1ms\n",
      "117:\tlearn: 0.3862099\ttotal: 200ms\tremaining: 54.3ms\n",
      "118:\tlearn: 0.3849541\ttotal: 202ms\tremaining: 52.5ms\n",
      "119:\tlearn: 0.3838958\ttotal: 204ms\tremaining: 51ms\n",
      "120:\tlearn: 0.3833400\ttotal: 206ms\tremaining: 49.3ms\n",
      "121:\tlearn: 0.3823875\ttotal: 208ms\tremaining: 47.7ms\n",
      "122:\tlearn: 0.3812073\ttotal: 210ms\tremaining: 46ms\n",
      "123:\tlearn: 0.3803443\ttotal: 211ms\tremaining: 44.3ms\n",
      "124:\tlearn: 0.3795023\ttotal: 212ms\tremaining: 42.5ms\n",
      "125:\tlearn: 0.3788703\ttotal: 214ms\tremaining: 40.7ms\n",
      "126:\tlearn: 0.3781814\ttotal: 215ms\tremaining: 38.9ms\n",
      "127:\tlearn: 0.3772617\ttotal: 216ms\tremaining: 37.2ms\n",
      "128:\tlearn: 0.3763688\ttotal: 219ms\tremaining: 35.6ms\n",
      "129:\tlearn: 0.3760365\ttotal: 221ms\tremaining: 34ms\n",
      "130:\tlearn: 0.3754408\ttotal: 223ms\tremaining: 32.4ms\n",
      "131:\tlearn: 0.3745684\ttotal: 225ms\tremaining: 30.7ms\n",
      "132:\tlearn: 0.3741271\ttotal: 226ms\tremaining: 28.8ms\n",
      "133:\tlearn: 0.3734072\ttotal: 227ms\tremaining: 27.2ms\n",
      "134:\tlearn: 0.3724872\ttotal: 229ms\tremaining: 25.4ms\n",
      "135:\tlearn: 0.3719429\ttotal: 230ms\tremaining: 23.7ms\n",
      "136:\tlearn: 0.3714803\ttotal: 232ms\tremaining: 22ms\n",
      "137:\tlearn: 0.3710894\ttotal: 236ms\tremaining: 20.5ms\n",
      "138:\tlearn: 0.3698048\ttotal: 238ms\tremaining: 18.8ms\n",
      "139:\tlearn: 0.3690040\ttotal: 239ms\tremaining: 17.1ms\n",
      "140:\tlearn: 0.3675594\ttotal: 241ms\tremaining: 15.4ms\n",
      "141:\tlearn: 0.3662167\ttotal: 243ms\tremaining: 13.7ms\n",
      "142:\tlearn: 0.3650063\ttotal: 244ms\tremaining: 12ms\n",
      "143:\tlearn: 0.3637456\ttotal: 246ms\tremaining: 10.2ms\n",
      "144:\tlearn: 0.3629865\ttotal: 247ms\tremaining: 8.52ms\n",
      "145:\tlearn: 0.3620773\ttotal: 250ms\tremaining: 6.85ms\n",
      "146:\tlearn: 0.3611610\ttotal: 252ms\tremaining: 5.14ms\n",
      "147:\tlearn: 0.3606295\ttotal: 253ms\tremaining: 3.42ms\n",
      "148:\tlearn: 0.3599331\ttotal: 255ms\tremaining: 1.71ms\n",
      "149:\tlearn: 0.3596620\ttotal: 256ms\tremaining: 0us\n",
      "Training accuracy score of CatBoost is =  87.8234398782344\n",
      "Test accuracy score of CatBoost is =  80.60606060606061\n"
     ]
    }
   ],
   "source": [
    "import catboost as Cat \n",
    "cb = Cat.CatBoostClassifier(random_state=7777, iterations=150, learning_rate=0.048)\n",
    "\n",
    "cb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = cb.predict(X_test)\n",
    "Y_train_pred = cb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of CatBoost is = \", acc1)\n",
    "print(\"Test accuracy score of CatBoost is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"CatBoost\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"CatBoost\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_up = pd.concat([training_result_up, dff1], ignore_index=True)\n",
    "test_result_up = pd.concat([test_result_up, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of XGBoost is =  100.0\n",
      "Test accuracy score of XGBoost is =  89.0909090909091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as XGBoost\n",
    "xgb = XGBoost.XGBClassifier()\n",
    "\n",
    "xgb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = xgb.predict(X_test)\n",
    "Y_train_pred = xgb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of XGBoost is = \", acc1)\n",
    "print(\"Test accuracy score of XGBoost is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"XGBoost\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"XGBoost\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_up = pd.concat([training_result_up, dff1], ignore_index=True)\n",
    "test_result_up = pd.concat([test_result_up, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                      Model    Accuracy\n",
       " 0                       KNN   74.124810\n",
       " 1             Random Forest  100.000000\n",
       " 2                       SVM   75.799087\n",
       " 3       Logistic Regression   72.146119\n",
       " 4      Gaussian Naive Bayes   73.363775\n",
       " 5   Multinomial Naive Bayes   64.840183\n",
       " 6     Bernoulli Naive Bayes   70.624049\n",
       " 7             Decision Tree   78.995434\n",
       " 8        Bagging Classifier   84.627093\n",
       " 9                  AdaBoost   82.952816\n",
       " 10        Gradient Boosting   92.085236\n",
       " 11                 CatBoost   87.823440\n",
       " 12                  XGBoost  100.000000,\n",
       "                       Model   Accuracy\n",
       " 0                       KNN  69.090909\n",
       " 1             Random Forest  90.909091\n",
       " 2                       SVM  74.545455\n",
       " 3       Logistic Regression  73.939394\n",
       " 4      Gaussian Naive Bayes  72.727273\n",
       " 5   Multinomial Naive Bayes  61.212121\n",
       " 6     Bernoulli Naive Bayes  77.575758\n",
       " 7             Decision Tree  73.939394\n",
       " 8        Bagging Classifier  80.606061\n",
       " 9                  AdaBoost  75.757576\n",
       " 10        Gradient Boosting  82.424242\n",
       " 11                 CatBoost  80.606061\n",
       " 12                  XGBoost  89.090909)"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_result_up, test_result_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_downsample.drop(['Loan_Status'],axis=1)\n",
    "Y = data_downsample['Loan_Status']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of KNN is =  70.23411371237458\n",
      "Test accuracy score of KNN is =  66.66666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanidhya\\AppData\\Local\\Temp\\ipykernel_5204\\427265734.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  training_result_down = pd.concat([training_result_down, dff1], ignore_index=True)\n",
      "C:\\Users\\Sanidhya\\AppData\\Local\\Temp\\ipykernel_5204\\427265734.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_result_down = pd.concat([test_result_down, dff2], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=25)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "\n",
    "Y_train_pred = knn.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of KNN is = \", acc1)\n",
    "print(\"Test accuracy score of KNN is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"KNN\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"KNN\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_down = pd.concat([training_result_down, dff1], ignore_index=True)\n",
    "test_result_down = pd.concat([test_result_down, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Random Forest is =  100.0\n",
      "Test accuracy score of Random Forest is =  81.33333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 96,criterion = 'entropy',\n",
    "                            random_state = 20, max_depth=50)\n",
    "rfc.fit(X_train, Y_train)\n",
    "Y_pred = rfc.predict(X_test)\n",
    "Y_train_pred = rfc.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Random Forest is = \", acc1)\n",
    "print(\"Test accuracy score of Random Forest is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"Random Forest\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Random Forest\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_down = pd.concat([training_result_down, dff1], ignore_index=True)\n",
    "test_result_down = pd.concat([test_result_down, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "svc = SVC(kernel='poly', degree=3)\n",
    "lc = LogisticRegression(max_iter = 221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of SVM is =  74.91638795986621\n",
      "Test accuracy score of SVM is =  68.0\n"
     ]
    }
   ],
   "source": [
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "Y_train_pred = svc.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of SVM is = \", acc1)\n",
    "print(\"Test accuracy score of SVM is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"SVM\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"SVM\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_down = pd.concat([training_result_down, dff1], ignore_index=True)\n",
    "test_result_down = pd.concat([test_result_down, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Logistic Regression is =  70.5685618729097\n",
      "Test accuracy score of Logistic Regression is =  72.0\n"
     ]
    }
   ],
   "source": [
    "lc.fit(X_train, Y_train)\n",
    "Y_pred = lc.predict(X_test)\n",
    "Y_train_pred = lc.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Logistic Regression is = \", acc1)\n",
    "print(\"Test accuracy score of Logistic Regression is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"Logistic Regression\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Logistic Regression\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_down = pd.concat([training_result_down, dff1], ignore_index=True)\n",
    "test_result_down = pd.concat([test_result_down, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Gaussian Naive Bayes is =  70.5685618729097\n",
      "Test accuracy score of Gaussian Naive Bayes is =  76.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = gnb.predict(X_test)\n",
    "Y_train_pred = gnb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Gaussian Naive Bayes is = \", acc1)\n",
    "print(\"Test accuracy score of Gaussian Naive Bayes is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"Gaussian Naive Bayes\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Gaussian Naive Bayes\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_down = pd.concat([training_result_down, dff1], ignore_index=True)\n",
    "test_result_down = pd.concat([test_result_down, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Multinomial Naive Bayes is =  66.22073578595318\n",
      "Test accuracy score of Multinomial Naive Bayes is =  66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = mnb.predict(X_test)\n",
    "Y_train_pred = mnb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Multinomial Naive Bayes is = \", acc1)\n",
    "print(\"Test accuracy score of Multinomial Naive Bayes is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"Multinomial Naive Bayes\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Multinomial Naive Bayes\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_down = pd.concat([training_result_down, dff1], ignore_index=True)\n",
    "test_result_down = pd.concat([test_result_down, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Bernoulli Naive Bayes is =  71.23745819397993\n",
      "Test accuracy score of Bernoulli Naive Bayes is =  70.66666666666667\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = bnb.predict(X_test)\n",
    "Y_train_pred = bnb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Bernoulli Naive Bayes is = \", acc1)\n",
    "print(\"Test accuracy score of Bernoulli Naive Bayes is = \", acc2)\n",
    "\n",
    "\n",
    "dict1 = {'Model': [\"Bernoulli Naive Bayes\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Bernoulli Naive Bayes\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_down = pd.concat([training_result_down, dff1], ignore_index=True)\n",
    "test_result_down = pd.concat([test_result_down, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Decision Tree is =  78.59531772575251\n",
      "Test accuracy score of Decision Tree is =  68.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=8, max_leaf_nodes=10, max_features=12, random_state=7777)\n",
    "dt.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = dt.predict(X_test)\n",
    "Y_train_pred = dt.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Decision Tree is = \", acc1)\n",
    "print(\"Test accuracy score of Decision Tree is = \", acc2)\n",
    "\n",
    "\n",
    "dict1 = {'Model': [\"Decision Tree\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Decision Tree\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_down = pd.concat([training_result_down, dff1], ignore_index=True)\n",
    "test_result_down = pd.concat([test_result_down, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Bagging Classifier is =  80.93645484949833\n",
      "Test accuracy score of Bagging Classifier is =  74.66666666666667\n"
     ]
    }
   ],
   "source": [
    "bg=BaggingClassifier(RandomForestClassifier(min_samples_split=5,max_depth=6),max_samples=0.5,max_features=1.0,n_estimators=10)\n",
    "bg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = bg.predict(X_test)\n",
    "Y_train_pred = bg.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Bagging Classifier is = \", acc1)\n",
    "print(\"Test accuracy score of Bagging Classifier is = \", acc2)\n",
    "\n",
    "\n",
    "dict1 = {'Model': [\"Bagging Classifier\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Bagging Classifier\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_down = pd.concat([training_result_down, dff1], ignore_index=True)\n",
    "test_result_down = pd.concat([test_result_down, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of AdaBoost is =  85.28428093645485\n",
      "Test accuracy score of AdaBoost is =  72.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = ada.predict(X_test)\n",
    "Y_train_pred = ada.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of AdaBoost is = \", acc1)\n",
    "print(\"Test accuracy score of AdaBoost is = \", acc2)\n",
    "\n",
    "\n",
    "dict1 = {'Model': [\"AdaBoost\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"AdaBoost\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_down = pd.concat([training_result_down, dff1], ignore_index=True)\n",
    "test_result_down = pd.concat([test_result_down, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of Gradient Boosting is =  95.31772575250837\n",
      "Test accuracy score of Gradient Boosting is =  74.66666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gdb = GradientBoostingClassifier(n_estimators=100)\n",
    "gdb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = gdb.predict(X_test)\n",
    "Y_train_pred = gdb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of Gradient Boosting is = \", acc1)\n",
    "print(\"Test accuracy score of Gradient Boosting is = \", acc2)\n",
    "\n",
    "\n",
    "dict1 = {'Model': [\"Gradient Boosting\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"Gradient Boosting\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_down = pd.concat([training_result_down, dff1], ignore_index=True)\n",
    "test_result_down = pd.concat([test_result_down, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6863496\ttotal: 2.37ms\tremaining: 353ms\n",
      "1:\tlearn: 0.6799834\ttotal: 4.3ms\tremaining: 318ms\n",
      "2:\tlearn: 0.6733992\ttotal: 5.61ms\tremaining: 275ms\n",
      "3:\tlearn: 0.6659032\ttotal: 7.18ms\tremaining: 262ms\n",
      "4:\tlearn: 0.6594365\ttotal: 8.41ms\tremaining: 244ms\n",
      "5:\tlearn: 0.6536141\ttotal: 9.55ms\tremaining: 229ms\n",
      "6:\tlearn: 0.6484056\ttotal: 10.8ms\tremaining: 220ms\n",
      "7:\tlearn: 0.6430681\ttotal: 12.4ms\tremaining: 220ms\n",
      "8:\tlearn: 0.6374109\ttotal: 14.2ms\tremaining: 223ms\n",
      "9:\tlearn: 0.6316975\ttotal: 16.2ms\tremaining: 227ms\n",
      "10:\tlearn: 0.6273098\ttotal: 17.5ms\tremaining: 222ms\n",
      "11:\tlearn: 0.6218606\ttotal: 18.7ms\tremaining: 215ms\n",
      "12:\tlearn: 0.6155411\ttotal: 19.9ms\tremaining: 210ms\n",
      "13:\tlearn: 0.6106946\ttotal: 21.1ms\tremaining: 205ms\n",
      "14:\tlearn: 0.6057783\ttotal: 22.2ms\tremaining: 200ms\n",
      "15:\tlearn: 0.6014610\ttotal: 23.3ms\tremaining: 195ms\n",
      "16:\tlearn: 0.5974987\ttotal: 24.5ms\tremaining: 191ms\n",
      "17:\tlearn: 0.5938996\ttotal: 25.5ms\tremaining: 187ms\n",
      "18:\tlearn: 0.5908143\ttotal: 26.9ms\tremaining: 185ms\n",
      "19:\tlearn: 0.5872548\ttotal: 29.2ms\tremaining: 190ms\n",
      "20:\tlearn: 0.5843799\ttotal: 31.1ms\tremaining: 191ms\n",
      "21:\tlearn: 0.5804814\ttotal: 32.2ms\tremaining: 188ms\n",
      "22:\tlearn: 0.5769373\ttotal: 33.4ms\tremaining: 184ms\n",
      "23:\tlearn: 0.5722149\ttotal: 34.5ms\tremaining: 181ms\n",
      "24:\tlearn: 0.5681047\ttotal: 35.6ms\tremaining: 178ms\n",
      "25:\tlearn: 0.5642675\ttotal: 36.8ms\tremaining: 175ms\n",
      "26:\tlearn: 0.5613805\ttotal: 37.9ms\tremaining: 173ms\n",
      "27:\tlearn: 0.5577972\ttotal: 39.1ms\tremaining: 170ms\n",
      "28:\tlearn: 0.5542629\ttotal: 40.4ms\tremaining: 169ms\n",
      "29:\tlearn: 0.5518314\ttotal: 42.3ms\tremaining: 169ms\n",
      "30:\tlearn: 0.5477815\ttotal: 43.9ms\tremaining: 169ms\n",
      "31:\tlearn: 0.5444830\ttotal: 45.5ms\tremaining: 168ms\n",
      "32:\tlearn: 0.5415055\ttotal: 46.9ms\tremaining: 166ms\n",
      "33:\tlearn: 0.5390685\ttotal: 48.2ms\tremaining: 164ms\n",
      "34:\tlearn: 0.5363089\ttotal: 49.4ms\tremaining: 162ms\n",
      "35:\tlearn: 0.5339925\ttotal: 49.9ms\tremaining: 158ms\n",
      "36:\tlearn: 0.5322234\ttotal: 51.4ms\tremaining: 157ms\n",
      "37:\tlearn: 0.5296327\ttotal: 53.2ms\tremaining: 157ms\n",
      "38:\tlearn: 0.5264848\ttotal: 55.3ms\tremaining: 157ms\n",
      "39:\tlearn: 0.5237460\ttotal: 57.5ms\tremaining: 158ms\n",
      "40:\tlearn: 0.5205986\ttotal: 59.2ms\tremaining: 157ms\n",
      "41:\tlearn: 0.5175496\ttotal: 60.7ms\tremaining: 156ms\n",
      "42:\tlearn: 0.5147909\ttotal: 61.9ms\tremaining: 154ms\n",
      "43:\tlearn: 0.5125515\ttotal: 63.2ms\tremaining: 152ms\n",
      "44:\tlearn: 0.5104526\ttotal: 64.6ms\tremaining: 151ms\n",
      "45:\tlearn: 0.5081760\ttotal: 66.2ms\tremaining: 150ms\n",
      "46:\tlearn: 0.5050620\ttotal: 67.3ms\tremaining: 148ms\n",
      "47:\tlearn: 0.5027064\ttotal: 68.6ms\tremaining: 146ms\n",
      "48:\tlearn: 0.5002348\ttotal: 69.8ms\tremaining: 144ms\n",
      "49:\tlearn: 0.4978662\ttotal: 70.8ms\tremaining: 142ms\n",
      "50:\tlearn: 0.4950947\ttotal: 72.5ms\tremaining: 141ms\n",
      "51:\tlearn: 0.4931508\ttotal: 74.1ms\tremaining: 140ms\n",
      "52:\tlearn: 0.4923638\ttotal: 75ms\tremaining: 137ms\n",
      "53:\tlearn: 0.4907313\ttotal: 76.4ms\tremaining: 136ms\n",
      "54:\tlearn: 0.4888879\ttotal: 77.3ms\tremaining: 133ms\n",
      "55:\tlearn: 0.4880854\ttotal: 78.4ms\tremaining: 132ms\n",
      "56:\tlearn: 0.4860451\ttotal: 79.5ms\tremaining: 130ms\n",
      "57:\tlearn: 0.4845815\ttotal: 80.5ms\tremaining: 128ms\n",
      "58:\tlearn: 0.4833695\ttotal: 81.5ms\tremaining: 126ms\n",
      "59:\tlearn: 0.4819478\ttotal: 82.8ms\tremaining: 124ms\n",
      "60:\tlearn: 0.4799747\ttotal: 84.2ms\tremaining: 123ms\n",
      "61:\tlearn: 0.4784268\ttotal: 85.4ms\tremaining: 121ms\n",
      "62:\tlearn: 0.4771795\ttotal: 86.4ms\tremaining: 119ms\n",
      "63:\tlearn: 0.4757158\ttotal: 88.8ms\tremaining: 119ms\n",
      "64:\tlearn: 0.4736373\ttotal: 90.4ms\tremaining: 118ms\n",
      "65:\tlearn: 0.4719087\ttotal: 91.6ms\tremaining: 117ms\n",
      "66:\tlearn: 0.4707286\ttotal: 92.9ms\tremaining: 115ms\n",
      "67:\tlearn: 0.4693562\ttotal: 94.1ms\tremaining: 113ms\n",
      "68:\tlearn: 0.4680415\ttotal: 95.2ms\tremaining: 112ms\n",
      "69:\tlearn: 0.4671918\ttotal: 96.5ms\tremaining: 110ms\n",
      "70:\tlearn: 0.4660715\ttotal: 97.7ms\tremaining: 109ms\n",
      "71:\tlearn: 0.4649487\ttotal: 98.7ms\tremaining: 107ms\n",
      "72:\tlearn: 0.4638718\ttotal: 99.8ms\tremaining: 105ms\n",
      "73:\tlearn: 0.4625465\ttotal: 101ms\tremaining: 104ms\n",
      "74:\tlearn: 0.4615345\ttotal: 102ms\tremaining: 102ms\n",
      "75:\tlearn: 0.4607589\ttotal: 105ms\tremaining: 102ms\n",
      "76:\tlearn: 0.4596603\ttotal: 106ms\tremaining: 101ms\n",
      "77:\tlearn: 0.4581787\ttotal: 108ms\tremaining: 99.5ms\n",
      "78:\tlearn: 0.4566763\ttotal: 109ms\tremaining: 98ms\n",
      "79:\tlearn: 0.4552046\ttotal: 110ms\tremaining: 96.6ms\n",
      "80:\tlearn: 0.4538767\ttotal: 112ms\tremaining: 95.1ms\n",
      "81:\tlearn: 0.4529597\ttotal: 113ms\tremaining: 93.3ms\n",
      "82:\tlearn: 0.4516972\ttotal: 114ms\tremaining: 91.7ms\n",
      "83:\tlearn: 0.4506142\ttotal: 115ms\tremaining: 90.2ms\n",
      "84:\tlearn: 0.4492310\ttotal: 116ms\tremaining: 88.7ms\n",
      "85:\tlearn: 0.4477727\ttotal: 117ms\tremaining: 87.3ms\n",
      "86:\tlearn: 0.4464039\ttotal: 119ms\tremaining: 86.5ms\n",
      "87:\tlearn: 0.4462741\ttotal: 120ms\tremaining: 84.6ms\n",
      "88:\tlearn: 0.4451952\ttotal: 121ms\tremaining: 83ms\n",
      "89:\tlearn: 0.4442165\ttotal: 122ms\tremaining: 81.5ms\n",
      "90:\tlearn: 0.4433478\ttotal: 123ms\tremaining: 80ms\n",
      "91:\tlearn: 0.4420077\ttotal: 125ms\tremaining: 78.7ms\n",
      "92:\tlearn: 0.4406145\ttotal: 126ms\tremaining: 77.3ms\n",
      "93:\tlearn: 0.4394956\ttotal: 127ms\tremaining: 75.9ms\n",
      "94:\tlearn: 0.4379466\ttotal: 129ms\tremaining: 74.5ms\n",
      "95:\tlearn: 0.4368276\ttotal: 130ms\tremaining: 73.1ms\n",
      "96:\tlearn: 0.4352242\ttotal: 131ms\tremaining: 71.7ms\n",
      "97:\tlearn: 0.4345160\ttotal: 133ms\tremaining: 70.6ms\n",
      "98:\tlearn: 0.4336683\ttotal: 135ms\tremaining: 69.3ms\n",
      "99:\tlearn: 0.4335357\ttotal: 135ms\tremaining: 67.5ms\n",
      "100:\tlearn: 0.4319716\ttotal: 136ms\tremaining: 66.1ms\n",
      "101:\tlearn: 0.4311414\ttotal: 137ms\tremaining: 64.7ms\n",
      "102:\tlearn: 0.4303617\ttotal: 139ms\tremaining: 63.4ms\n",
      "103:\tlearn: 0.4294892\ttotal: 140ms\tremaining: 62ms\n",
      "104:\tlearn: 0.4286704\ttotal: 142ms\tremaining: 60.6ms\n",
      "105:\tlearn: 0.4278811\ttotal: 143ms\tremaining: 59.2ms\n",
      "106:\tlearn: 0.4271876\ttotal: 144ms\tremaining: 57.7ms\n",
      "107:\tlearn: 0.4260531\ttotal: 145ms\tremaining: 56.3ms\n",
      "108:\tlearn: 0.4247456\ttotal: 146ms\tremaining: 54.9ms\n",
      "109:\tlearn: 0.4237399\ttotal: 147ms\tremaining: 53.5ms\n",
      "110:\tlearn: 0.4223971\ttotal: 150ms\tremaining: 52.5ms\n",
      "111:\tlearn: 0.4212350\ttotal: 151ms\tremaining: 51.2ms\n",
      "112:\tlearn: 0.4199185\ttotal: 152ms\tremaining: 49.8ms\n",
      "113:\tlearn: 0.4187661\ttotal: 154ms\tremaining: 48.6ms\n",
      "114:\tlearn: 0.4180566\ttotal: 155ms\tremaining: 47.2ms\n",
      "115:\tlearn: 0.4159868\ttotal: 156ms\tremaining: 45.8ms\n",
      "116:\tlearn: 0.4149801\ttotal: 157ms\tremaining: 44.4ms\n",
      "117:\tlearn: 0.4137885\ttotal: 159ms\tremaining: 43ms\n",
      "118:\tlearn: 0.4126064\ttotal: 160ms\tremaining: 41.6ms\n",
      "119:\tlearn: 0.4112750\ttotal: 161ms\tremaining: 40.2ms\n",
      "120:\tlearn: 0.4098586\ttotal: 162ms\tremaining: 38.8ms\n",
      "121:\tlearn: 0.4089242\ttotal: 164ms\tremaining: 37.7ms\n",
      "122:\tlearn: 0.4080137\ttotal: 166ms\tremaining: 36.5ms\n",
      "123:\tlearn: 0.4065940\ttotal: 168ms\tremaining: 35.1ms\n",
      "124:\tlearn: 0.4060748\ttotal: 169ms\tremaining: 33.8ms\n",
      "125:\tlearn: 0.4054964\ttotal: 170ms\tremaining: 32.4ms\n",
      "126:\tlearn: 0.4039501\ttotal: 171ms\tremaining: 31ms\n",
      "127:\tlearn: 0.4031068\ttotal: 173ms\tremaining: 29.6ms\n",
      "128:\tlearn: 0.4022682\ttotal: 174ms\tremaining: 28.3ms\n",
      "129:\tlearn: 0.4018695\ttotal: 175ms\tremaining: 26.9ms\n",
      "130:\tlearn: 0.3999904\ttotal: 176ms\tremaining: 25.6ms\n",
      "131:\tlearn: 0.3993829\ttotal: 178ms\tremaining: 24.3ms\n",
      "132:\tlearn: 0.3973677\ttotal: 180ms\tremaining: 23ms\n",
      "133:\tlearn: 0.3966793\ttotal: 182ms\tremaining: 21.7ms\n",
      "134:\tlearn: 0.3950953\ttotal: 183ms\tremaining: 20.3ms\n",
      "135:\tlearn: 0.3944214\ttotal: 184ms\tremaining: 19ms\n",
      "136:\tlearn: 0.3940731\ttotal: 185ms\tremaining: 17.6ms\n",
      "137:\tlearn: 0.3932650\ttotal: 187ms\tremaining: 16.2ms\n",
      "138:\tlearn: 0.3924185\ttotal: 188ms\tremaining: 14.9ms\n",
      "139:\tlearn: 0.3918308\ttotal: 189ms\tremaining: 13.5ms\n",
      "140:\tlearn: 0.3905561\ttotal: 190ms\tremaining: 12.1ms\n",
      "141:\tlearn: 0.3897449\ttotal: 191ms\tremaining: 10.8ms\n",
      "142:\tlearn: 0.3886941\ttotal: 194ms\tremaining: 9.49ms\n",
      "143:\tlearn: 0.3876945\ttotal: 195ms\tremaining: 8.14ms\n",
      "144:\tlearn: 0.3873258\ttotal: 198ms\tremaining: 6.81ms\n",
      "145:\tlearn: 0.3863727\ttotal: 199ms\tremaining: 5.45ms\n",
      "146:\tlearn: 0.3849627\ttotal: 201ms\tremaining: 4.09ms\n",
      "147:\tlearn: 0.3835911\ttotal: 202ms\tremaining: 2.73ms\n",
      "148:\tlearn: 0.3826910\ttotal: 204ms\tremaining: 1.37ms\n",
      "149:\tlearn: 0.3821890\ttotal: 205ms\tremaining: 0us\n",
      "Training accuracy score of CatBoost is =  87.29096989966555\n",
      "Test accuracy score of CatBoost is =  76.0\n"
     ]
    }
   ],
   "source": [
    "import catboost as Cat \n",
    "cb = Cat.CatBoostClassifier(random_state=7777, iterations=150, learning_rate=0.048)\n",
    "\n",
    "cb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = cb.predict(X_test)\n",
    "Y_train_pred = cb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of CatBoost is = \", acc1)\n",
    "print(\"Test accuracy score of CatBoost is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"CatBoost\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"CatBoost\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_down = pd.concat([training_result_down, dff1], ignore_index=True)\n",
    "test_result_down = pd.concat([test_result_down, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score of XGBoost is =  100.0\n",
      "Test accuracy score of XGBoost is =  78.66666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as XGBoost\n",
    "xgb = XGBoost.XGBClassifier()\n",
    "\n",
    "xgb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = xgb.predict(X_test)\n",
    "Y_train_pred = xgb.predict(X_train)\n",
    "\n",
    "acc1 = 100*metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "acc2 = 100*metrics.accuracy_score(Y_test, Y_pred)\n",
    "print(\"Training accuracy score of XGBoost is = \", acc1)\n",
    "print(\"Test accuracy score of XGBoost is = \", acc2)\n",
    "\n",
    "dict1 = {'Model': [\"XGBoost\"], 'Accuracy': [acc1]}\n",
    "dict2 = {'Model': [\"XGBoost\"], 'Accuracy': [acc2]}\n",
    "\n",
    "dff1 = pd.DataFrame(dict1)\n",
    "dff2 = pd.DataFrame(dict2)\n",
    "\n",
    "training_result_down = pd.concat([training_result_down, dff1], ignore_index=True)\n",
    "test_result_down = pd.concat([test_result_down, dff2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_result</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_result_up</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_result_down</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>76.778243</td>\n",
       "      <td>KNN</td>\n",
       "      <td>74.124810</td>\n",
       "      <td>KNN</td>\n",
       "      <td>70.234114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>79.916318</td>\n",
       "      <td>SVM</td>\n",
       "      <td>75.799087</td>\n",
       "      <td>SVM</td>\n",
       "      <td>74.916388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>79.707113</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>72.146119</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>70.568562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>79.288703</td>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>73.363775</td>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>70.568562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>69.246862</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>64.840183</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>66.220736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>79.916318</td>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>70.624049</td>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>71.237458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>82.008368</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>78.995434</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>78.595318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>80.125523</td>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>84.627093</td>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>80.936455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>84.937238</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>82.952816</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>85.284281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>88.912134</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>92.085236</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>95.317726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>80.962343</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>87.823440</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>87.290970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            training_result                   training_result_up              \\\n",
       "                      Model    Accuracy                    Model    Accuracy   \n",
       "0                       KNN   76.778243                      KNN   74.124810   \n",
       "1             Random Forest  100.000000            Random Forest  100.000000   \n",
       "2                       SVM   79.916318                      SVM   75.799087   \n",
       "3       Logistic Regression   79.707113      Logistic Regression   72.146119   \n",
       "4      Gaussian Naive Bayes   79.288703     Gaussian Naive Bayes   73.363775   \n",
       "5   Multinomial Naive Bayes   69.246862  Multinomial Naive Bayes   64.840183   \n",
       "6     Bernoulli Naive Bayes   79.916318    Bernoulli Naive Bayes   70.624049   \n",
       "7             Decision Tree   82.008368            Decision Tree   78.995434   \n",
       "8        Bagging Classifier   80.125523       Bagging Classifier   84.627093   \n",
       "9                  AdaBoost   84.937238                 AdaBoost   82.952816   \n",
       "10        Gradient Boosting   88.912134        Gradient Boosting   92.085236   \n",
       "11                 CatBoost   80.962343                 CatBoost   87.823440   \n",
       "12                  XGBoost  100.000000                  XGBoost  100.000000   \n",
       "\n",
       "       training_result_down              \n",
       "                      Model    Accuracy  \n",
       "0                       KNN   70.234114  \n",
       "1             Random Forest  100.000000  \n",
       "2                       SVM   74.916388  \n",
       "3       Logistic Regression   70.568562  \n",
       "4      Gaussian Naive Bayes   70.568562  \n",
       "5   Multinomial Naive Bayes   66.220736  \n",
       "6     Bernoulli Naive Bayes   71.237458  \n",
       "7             Decision Tree   78.595318  \n",
       "8        Bagging Classifier   80.936455  \n",
       "9                  AdaBoost   85.284281  \n",
       "10        Gradient Boosting   95.317726  \n",
       "11                 CatBoost   87.290970  \n",
       "12                  XGBoost  100.000000  "
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_result.columns = pd.MultiIndex.from_product([['training_result'], training_result.columns])\n",
    "training_result_up.columns = pd.MultiIndex.from_product([['training_result_up'], training_result_up.columns])\n",
    "training_result_down.columns = pd.MultiIndex.from_product([['training_result_down'], training_result_down.columns])\n",
    "combined_df = pd.concat([training_result, training_result_up, training_result_down], axis=1)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_result</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_result_up</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_result_down</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>KNN</td>\n",
       "      <td>69.090909</td>\n",
       "      <td>KNN</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>81.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>85.833333</td>\n",
       "      <td>SVM</td>\n",
       "      <td>74.545455</td>\n",
       "      <td>SVM</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>85.833333</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>73.939394</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>72.727273</td>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>74.166667</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>61.212121</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>77.575758</td>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>70.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>80.833333</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>73.939394</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>80.606061</td>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>74.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>79.166667</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>75.757576</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>81.666667</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>82.424242</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>74.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>85.833333</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>80.606061</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>89.090909</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>78.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                test_result                      test_result_up             \\\n",
       "                      Model   Accuracy                    Model   Accuracy   \n",
       "0                       KNN  83.333333                      KNN  69.090909   \n",
       "1             Random Forest  83.333333            Random Forest  90.909091   \n",
       "2                       SVM  85.833333                      SVM  74.545455   \n",
       "3       Logistic Regression  85.833333      Logistic Regression  73.939394   \n",
       "4      Gaussian Naive Bayes  83.333333     Gaussian Naive Bayes  72.727273   \n",
       "5   Multinomial Naive Bayes  74.166667  Multinomial Naive Bayes  61.212121   \n",
       "6     Bernoulli Naive Bayes  83.333333    Bernoulli Naive Bayes  77.575758   \n",
       "7             Decision Tree  80.833333            Decision Tree  73.939394   \n",
       "8        Bagging Classifier  85.000000       Bagging Classifier  80.606061   \n",
       "9                  AdaBoost  79.166667                 AdaBoost  75.757576   \n",
       "10        Gradient Boosting  81.666667        Gradient Boosting  82.424242   \n",
       "11                 CatBoost  85.833333                 CatBoost  80.606061   \n",
       "12                  XGBoost  77.500000                  XGBoost  89.090909   \n",
       "\n",
       "           test_result_down             \n",
       "                      Model   Accuracy  \n",
       "0                       KNN  66.666667  \n",
       "1             Random Forest  81.333333  \n",
       "2                       SVM  68.000000  \n",
       "3       Logistic Regression  72.000000  \n",
       "4      Gaussian Naive Bayes  76.000000  \n",
       "5   Multinomial Naive Bayes  66.666667  \n",
       "6     Bernoulli Naive Bayes  70.666667  \n",
       "7             Decision Tree  68.000000  \n",
       "8        Bagging Classifier  74.666667  \n",
       "9                  AdaBoost  72.000000  \n",
       "10        Gradient Boosting  74.666667  \n",
       "11                 CatBoost  76.000000  \n",
       "12                  XGBoost  78.666667  "
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result.columns = pd.MultiIndex.from_product([['test_result'], test_result.columns])\n",
    "test_result_up.columns = pd.MultiIndex.from_product([['test_result_up'], test_result_up.columns])\n",
    "test_result_down.columns = pd.MultiIndex.from_product([['test_result_down'], test_result_down.columns])\n",
    "combined_df = pd.concat([test_result, test_result_up, test_result_down], axis=1)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
